import tkinter as tk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
import openCV as cv2
import googletrans

# Load the dataset of news articles.
df = pd.read_csv("news_articles.csv")

# Clean the data.
df = df.dropna()
df = df.reset_index(drop=True)

# Extract features.
tfidf_vectorizer = TfidfVectorizer()
X = tfidf_vectorizer.fit_transform(df["text"])
y = df["label"]

# Train the models.
models = [LogisticRegression(), MultinomialNB(), SVC()]
for model in models:
    model.fit(X, y)

# Create the GUI.
root = tk.Tk()
root.title("Fake News Detection")

# Create a text box for the article.
article_text = tk.Text(root, height=10, width=40)
article_text.grid(row=0, column=0)

# Create a button to predict the label of the article.
predict_button = tk.Button(root, text="Predict", command=lambda: predict())
predict_button.grid(row=1, column=0)

# Create a label to display the prediction.
prediction_label = tk.Label(root)
prediction_label.grid(row=2, column=0)

# Create a label to display instructions.
instructions_label = tk.Label(root, text="Enter a news article in the text box and click the 'Predict' button to see the prediction.")
instructions_label.grid(row=3, column=0)

# Create a button to save the prediction.
save_button = tk.Button(root, text="Save", command=lambda: save())
save_button.grid(row=4, column=0)

# Create a label to display the saved predictions.
saved_predictions_label = tk.Label(root)
saved_predictions_label.grid(row=5, column=0)

def predict():
    article = article_text.get("1.0", "end-1c")
    predictions = []
    for model in models:
        prediction = model.predict([article])
        predictions.append(prediction)
    prediction_label.config(text=predictions)

def save():
    predictions = prediction_label.cget("text")
    with open("saved_predictions.txt", "w") as f:
        f.write(predictions)

# Start the GUI.
root.mainloop()
